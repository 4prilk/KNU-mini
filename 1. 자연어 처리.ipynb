{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.__version__\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFGPT2Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>상품명</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미래의 물리학</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이기적 유전자</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>얽힘의 시대</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>마음의 과학</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>인체 완전판</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       상품명  label\n",
       "0  미래의 물리학      1\n",
       "1  이기적 유전자      1\n",
       "2   얽힘의 시대      1\n",
       "3   마음의 과학      1\n",
       "4   인체 완전판      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Science.csv',encoding='cp949')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.sample(frac=0.8, random_state=100)\n",
    "test_data = data.drop(train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 제목 개수 : 7624\n",
      "테스트용 제목 개수 : 1906\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 제목 개수 :',len(train_data))\n",
    "print('테스트용 제목 개수 :',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 토크나이징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', pad_token='<pad>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7624/7624 [00:00<00:00, 8250.06it/s]\n",
      "100%|██████████| 1906/1906 [00:00<00:00, 7676.28it/s]\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 128\n",
    "def convert_examples_to_features(examples, labels, max_seq_len, tokenizer):\n",
    "\n",
    "    input_ids, data_labels = [], []\n",
    "    \n",
    "    for example, label in tqdm(zip(examples, labels), total=len(examples)):\n",
    "\n",
    "        bos_token = [tokenizer.bos_token]\n",
    "        eos_token = [tokenizer.eos_token]\n",
    "        tokens = bos_token + tokenizer.tokenize(example) + eos_token\n",
    "        input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_id = pad_sequences([input_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
    "\n",
    "        assert len(input_id) == max_seq_len, \"Error with input length {} vs {}\".format(len(input_id), max_seq_len)\n",
    "        input_ids.append(input_id)\n",
    "        data_labels.append(label)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    data_labels = np.asarray(data_labels, dtype=np.int32)\n",
    "\n",
    "    return input_ids, data_labels\n",
    "\n",
    "train_X, train_y = convert_examples_to_features(train_data['상품명'], train_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)\n",
    "\n",
    "test_X, test_y = convert_examples_to_features(test_data['상품명'], test_data['label'], max_seq_len=max_seq_len, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어에 대한 정수 인코딩 : [    1 28236  6921 10639 10818  9094 26224 11649 10977 17161     1     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3     3     3     3     3\n",
      "     3     3     3     3     3     3     3     3]\n",
      "각 인코딩의 길이 : 128\n",
      "정수 인코딩 복원 : </s> 미생물군 유전체는 내몸을 어떻게 바꾸는가</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "레이블 : 1\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이: 128\n",
    "input_id = train_X[0]\n",
    "label = train_y[0]\n",
    "\n",
    "print('단어에 대한 정수 인코딩 :',input_id)\n",
    "print('각 인코딩의 길이 :', len(input_id))\n",
    "print('정수 인코딩 복원 :',tokenizer.decode(input_id))\n",
    "print('레이블 :',label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.7.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'lm_head.weight', 'transformer.h.10.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.5.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFBaseModelOutputWithPastAndCrossAttentions(last_hidden_state=<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'tfgpt2_model_1')>, past_key_values=(<KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>), hidden_states=None, attentions=None, cross_attentions=None)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 128, 768), dtype=tf.float32, name=None), name='tfgpt2_model_1/transformer/Reshape_2:0', description=\"created by layer 'tfgpt2_model_1'\")\n",
      "(<KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>, <KerasTensor: shape=(2, None, 12, 128, 64) dtype=float32 (created by layer 'tfgpt2_model_1')>)\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf.__operators__.getitem/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem'\")\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2Model.from_pretrained('skt/kogpt2-base-v2', from_pt=True)\n",
    "\n",
    "max_seq_len = 128\n",
    "\n",
    "input_ids_layer = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32)\n",
    "outputs = model([input_ids_layer])\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "print(outputs[0])\n",
    "\n",
    "print(outputs[1])\n",
    "\n",
    "print(outputs[0][:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFGPT2ForSequenceClassification(tf.keras.Model):\n",
    "    def __init__(self, model_name):\n",
    "        super(TFGPT2ForSequenceClassification, self).__init__()\n",
    "        self.gpt = TFGPT2Model.from_pretrained(model_name, from_pt=True)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "        self.classifier = tf.keras.layers.Dense(1,\n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02),\n",
    "                                                activation='sigmoid',\n",
    "                                                name='classifier')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = self.gpt(input_ids=inputs)\n",
    "        cls_token = outputs[0][:, -1]\n",
    "        cls_token = self.dropout(cls_token)\n",
    "        prediction = self.classifier(cls_token)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2Model: ['transformer.h.7.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'lm_head.weight', 'transformer.h.10.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.5.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2Model from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2Model from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2Model were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFGPT2ForSequenceClassification(\"skt/kogpt2-base-v2\")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "382/382 [==============================] - 4337s 11s/step - loss: 0.6320 - accuracy: 0.6475 - val_loss: 0.6203 - val_accuracy: 0.6623\n",
      "Epoch 2/2\n",
      "382/382 [==============================] - 4319s 11s/step - loss: 0.5454 - accuracy: 0.7245 - val_loss: 0.6873 - val_accuracy: 0.6518\n",
      "2/2 [==============================] - 352s 160s/step - loss: 0.6688 - accuracy: 0.6569\n",
      "test loss, test acc:  [0.6688129305839539, 0.6568730473518372]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_y, epochs=2, batch_size=16, validation_split=0.2)\n",
    "\n",
    "results = model.evaluate(test_X, test_y, batch_size=1024)\n",
    "print(\"test loss, test acc: \", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "\n",
    "  bos_token = [tokenizer.bos_token]\n",
    "  eos_token = [tokenizer.eos_token]\n",
    "  tokens = bos_token + tokenizer.tokenize(new_sentence) + eos_token\n",
    "  input_id = tokenizer.convert_tokens_to_ids(tokens)\n",
    "  input_id = pad_sequences([input_id], maxlen=max_seq_len, value=tokenizer.pad_token_id, padding='post')[0]\n",
    "  input_id = np.array([input_id])\n",
    "  score = model.predict(input_id)[0][0]\n",
    "\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 베스트셀러입니다.\\n\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 워스트셀러입니다.\\n\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.78% 확률로 베스트셀러입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('거의 모든 것의 역사')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
